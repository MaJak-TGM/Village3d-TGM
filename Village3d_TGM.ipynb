{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files "
      ],
      "metadata": {
        "id": "6eQYcxpEW6u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateModel(archive, training, test, n_classes, name_model):\n",
        "  !unzip TGM-Images_0.5.zip\n",
        "\n",
        "  batch_size=256\n",
        "  image_size=(224, 224)\n",
        "\n",
        "  train_dataset = image_dataset_from_directory(training,\n",
        "                                               subset='training',\n",
        "                                               seed=42,\n",
        "                                               validation_split=0.1,\n",
        "                                               batch_size=batch_size,\n",
        "                                               image_size=image_size)\n",
        "\n",
        "  validation_dataset = image_dataset_from_directory(training,\n",
        "                                               subset='validation',\n",
        "                                               seed=42,\n",
        "                                               validation_split=0.1,\n",
        "                                               batch_size=batch_size,\n",
        "                                               image_size=image_size)\n",
        "\n",
        "  test_dataset = image_dataset_from_directory(test,\n",
        "                                               batch_size=batch_size,\n",
        "                                               image_size=image_size)\n",
        "\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "  train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "  validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "  test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(16, (5, 5), padding='same', \n",
        "                 input_shape=(224, 224, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  history = model.fit(train_dataset, \n",
        "                    validation_data=validation_dataset,\n",
        "                    epochs=5,\n",
        "                    verbose=2)\n",
        "\n",
        "  model.save(name_model)"
      ],
      "metadata": {
        "id": "FvALr5VBSwbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3KyQO1vNnYY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EmptyGrid(image, grid):\n",
        "  img = cv2.imread(image)\n",
        "  size_x = np.size(img, 1)\n",
        "  size_y = np.size(img, 0)\n",
        "  gr_x = size_x\n",
        "  gr_y = size_y\n",
        "  img_grd = img\n",
        "  for a in range(1, grid+1):\n",
        "    gr_x = round(gr_x/2)\n",
        "    gr_y = round(gr_y/2)\n",
        "    for i in range(0, 2**a):\n",
        "      for j in range(0,2**a):\n",
        "        x1 = gr_x*i\n",
        "        x2 = x1+gr_x\n",
        "        y1 = gr_y*j\n",
        "        y2 = y1+gr_y\n",
        "        cv2.rectangle(img_grd, (x1,y1),(x2,y2),(255,255,255), 2)\n",
        "  img_grd = cv2.cvtColor(img_grd, cv2.COLOR_RGB2BGR)\n",
        "  plt.imshow(img_grd)"
      ],
      "metadata": {
        "id": "dt0iDSaPnijo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SmartGrid(model, labels, image, grid):\n",
        "  np.set_printoptions(suppress=True)\n",
        "  model = tf.keras.models.load_model(model, compile=False)\n",
        "  class_names = open(labels, \"r\").readlines()\n",
        "  img_a = cv2.imread(image)\n",
        "  size_x = np.size(img_a, 1)\n",
        "  size_y = np.size(img_a, 0)\n",
        "  gr_x = size_x\n",
        "  gr_y = size_y\n",
        "  img_grd = img_a\n",
        "  for a in range(1, grid+1):\n",
        "    gr_x = round(gr_x/2)\n",
        "    gr_y = round(gr_y/2)\n",
        "    for i in range(0, 2**a):\n",
        "      for j in range(0,2**a):\n",
        "        x1 = gr_x*i\n",
        "        x2 = x1+gr_x\n",
        "        y1 = gr_y*j\n",
        "        y2 = y1+gr_y\n",
        "        cntr = [(x1+x2)/2, (y1+y2)/2]\n",
        "        img_b = cv2.imread(image)\n",
        "        img_b = img_b[y1:y2, x1:x2]\n",
        "        img_b = cv2.resize(img_b, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "        img_b = np.asarray(img_b, dtype=np.float32).reshape(1, 224, 224, 3)\n",
        "        img_b = (img_b / 127.5) - 1\n",
        "        prediction = model.predict(img_b)\n",
        "        index = np.argmax(prediction)\n",
        "        class_name = class_names[index].strip()\n",
        "        confidence_score = prediction[0][index]\n",
        "        R = int((index % 2) * 255)\n",
        "        G = int((index % 3) * 127)\n",
        "        B = int((index % 4) * 84)        \n",
        "        cv2.rectangle(img_grd, (x1+5,y1+5),(x2-5,y2-5),(R,G,B), 5)\n",
        "        text_color = (255-R, 255-G, 255-B)\n",
        "        cv2.putText(img_grd, class_name, (x1+10, y2-10), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n",
        "  img_grd = cv2.cvtColor(img_grd, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(img_grd)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uQhUlEdHsTuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SmartList(model, labels, house, image, grid):\n",
        "  np.set_printoptions(suppress=True)\n",
        "  model = load_model(model, compile=False)\n",
        "  class_names = open(labels, \"r\").readlines()\n",
        "  img_a = cv2.imread(image)\n",
        "  size_x = np.size(img_a, 1)\n",
        "  size_y = np.size(img_a, 0)\n",
        "  gr_x = size_x\n",
        "  gr_y = size_y\n",
        "  img_grd = img_a\n",
        "  cntrs = []\n",
        "  for a in range(1, grid+1):\n",
        "    gr_x = round(gr_x/2)\n",
        "    gr_y = round(gr_y/2)\n",
        "    for i in range(0, 2**a):\n",
        "      for j in range(0,2**a):\n",
        "        x1 = gr_x*i\n",
        "        x2 = x1+gr_x\n",
        "        y1 = gr_y*j\n",
        "        y2 = y1+gr_y\n",
        "        xc = round((x1+x2)/2, 0)\n",
        "        yc = round((y1+y2)/2, 0)\n",
        "        cntr = [xc, yc]\n",
        "        img_b = cv2.imread(image)\n",
        "        img_b = img_b[y1:y2, x1:x2]\n",
        "        img_b = cv2.resize(img_b, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "        img_b = np.asarray(img_b, dtype=np.float32).reshape(1, 224, 224, 3)\n",
        "        img_b = (img_b / 127.5) - 1\n",
        "        prediction = model.predict(img_b)\n",
        "        index = np.argmax(prediction)\n",
        "        confidence_score = prediction[0][index]\n",
        "        if index == house:\n",
        "          cv2.rectangle(img_grd, (x1+5,y1+5),(x2-5,y2-5),(100,100,100), 5)\n",
        "          cntrs.append(cntr)\n",
        "  return(cntrs)"
      ],
      "metadata": {
        "id": "Im489WTVj35e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcoA3VTk7PG",
        "outputId": "82438295-efee-4167-ea5d-a317081b2ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trimesh\n",
            "  Downloading trimesh-3.21.5-py3-none-any.whl (680 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.8/680.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.22.4)\n",
            "Installing collected packages: trimesh\n",
            "Successfully installed trimesh-3.21.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import trimesh\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-cZvNr7F7uuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def STL_byList(cntrs, x, y, scale, stl):\n",
        "  \n",
        "  plane = trimesh.primitives.Box([x, y, 0.01])\n",
        "\n",
        "  mesh = trimesh.load(stl)\n",
        "  mesh.apply_scale(scale)\n",
        "\n",
        "  for i in cntrs:\n",
        "      x1 = i[0]-x/2\n",
        "      y1 = i[1]-y/2\n",
        "      newmesh = mesh.copy()\n",
        "      newmesh.vertices[:, :2] += np.array([x1, y1])\n",
        "      plane = trimesh.util.concatenate([plane, newmesh])\n",
        "  scene = trimesh.Scene(plane)\n",
        "  return(scene).show()"
      ],
      "metadata": {
        "id": "0iljYsFL7-_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def STL_byImage(model, labels, house, image, grid, scale, stl):\n",
        "  cntrs = SmartList(model, labels, house, image, grid)\n",
        "  image = cv2.imread(image)\n",
        "  x = np.size(image, 1)\n",
        "  y = np.size(image, 0)\n",
        "  plane = trimesh.primitives.Box([x, y, 0.01])\n",
        "  mesh = trimesh.load(stl)\n",
        "  mesh.apply_scale(scale)\n",
        "  for i in cntrs:\n",
        "    x1 = i[0]-x/2\n",
        "    y1 = i[1]-y/2\n",
        "    newmesh = mesh.copy()\n",
        "    newmesh.vertices[:, :2] += np.array([x1, y1])\n",
        "    plane = trimesh.util.concatenate([plane, newmesh])\n",
        "  scene = trimesh.Scene(plane)\n",
        "  return(scene).show()"
      ],
      "metadata": {
        "id": "YugY-ujjWwvf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}